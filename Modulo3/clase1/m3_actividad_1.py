# -*- coding: utf-8 -*-
"""M3.ACTIVIDAD 1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12ATwhFVYvTedtFTXBzTT2UVcRGraZ2W1
"""

#pip install numpy

import numpy as np

#Genera un arreglo 3D llamado D de tamaño (30, 96, 3), con datos aleatorios de sensores:
# • Temperatura: entre 5°C y 110°C
# • Presión: entre 80 y 140 kPa
# • Humedad: entre 15% y 85%
# (Usa np.random.uniform para cada canal y concatena por la tercera dimensión)

#tupla
dimensiones = (30, 96)

# generamos los datos aleatorios según dimensiones
temperatura = np.random.uniform(5, 110, size=dimensiones)
presion = np.random.uniform(80, 140, size=dimensiones)
humedad = np.random.uniform(15, 85, size=dimensiones)

# Secuencia de arreglos que tiene las mismas dimensiones
D = np.stack([temperatura, presion, humedad], axis=-1)

# imprime dimensiones resultantes
print("Dimensiones del array D:", D.ndim)
# Justificación: Creación del conjunto de datos simulado para el análisis.

#Introduce valores perdidos y atípicos:
# • Escoge aleatoriamente 30 valores del arreglo total y asígnales np.nan (simulando sensores
# defectuosos).
# • Introduce valores extremos (3 valores mayores al rango superior y 3 menores al rango inferior en
# cada canal).

# Introduce valores perdidos
num_valores_perdidos = 30
indices_perdidos = np.random.choice(D.size, num_valores_perdidos, replace=False)
D_flat = D.ravel()
D_flat[indices_perdidos] = np.nan
D = D_flat.reshape(D.shape)

# Introduce valores atípicos
num_valores_atipicos = 3
canales = D.shape[-1]

for canal in range(canales):
  # Valores atípicos mayores
  indices_atipicos_mayores = np.random.choice(D[:, :, canal].size, num_valores_atipicos, replace=False)
  D_canal_flat = D[:, :, canal].ravel()
  if canal == 0: # Temperatura
    D_canal_flat[indices_atipicos_mayores] = np.random.uniform(120, 150, size=num_valores_atipicos)
  elif canal == 1: # Presión
    D_canal_flat[indices_atipicos_mayores] = np.random.uniform(150, 180, size=num_valores_atipicos)
  elif canal == 2: # Humedad
    D_canal_flat[indices_atipicos_mayores] = np.random.uniform(90, 110, size=num_valores_atipicos)
  D[:, :, canal] = D_canal_flat.reshape(D[:, :, canal].shape)

  # Valores atípicos menores
  indices_atipicos_menores = np.random.choice(D[:, :, canal].size, num_valores_atipicos, replace=False)
  D_canal_flat = D[:, :, canal].ravel()
  if canal == 0: # Temperatura
    D_canal_flat[indices_atipicos_menores] = np.random.uniform(-20, 0, size=num_valores_atipicos)
  elif canal == 1: # Presión
    D_canal_flat[indices_atipicos_menores] = np.random.uniform(30, 70, size=num_valores_atipicos)
  elif canal == 2: # Humedad
    D_canal_flat[indices_atipicos_menores] = np.random.uniform(0, 10, size=num_valores_atipicos)
  D[:, :, canal] = D_canal_flat.reshape(D[:, :, canal].shape)

print("\nArray D con valores perdidos y atípicos:")
D
# Justificación: Se simulan problemas comunes en los datos reales para practicar su manejo.







# 3.1. Contar valores perdidos por variable
nans_por_var = np.isnan(D).sum(axis=(0,1))
print("\nValores perdidos por variable (Temp, Pres, Hum):", nans_por_var)
# Justificación: Es importante conocer la magnitud del problema de datos faltantes antes de imputar.

# Definimos el número de sensores y variables para usar en el siguiente paso
n_sensores = D.shape[0]
n_vars = D.shape[-1]

# 3.2. Imputar valores perdidos con la media de la variable por sensor
for sensor in range(n_sensores):
    for var in range(n_vars):
        sensor_var = D[sensor, :, var]
        mean_val = np.nanmean(sensor_var)
        D[sensor, np.isnan(sensor_var), var] = mean_val
# Justificación: Imputar por sensor mantiene la individualidad de cada dispositivo.

# 4.1. Sensores con temp. máxima > 100°C y humedad mínima < 20%
temp_max = np.nanmax(D[:, :, 0], axis=1)
hum_min = np.nanmin(D[:, :, 2], axis=1)
cond = (temp_max > 100) & (hum_min < 20)
sensores_filtrados = np.where(cond)[0]
print("\nSensores que cumplen ambas condiciones:", sensores_filtrados)
print("Cantidad de sensores filtrados:", len(sensores_filtrados))
# Justificación: Este filtro selecciona sensores con condiciones extremas de operación.

# 5.1. Normalizar presión a [0,1] por sensor
pres_min = np.min(D[:, :, 1], axis=1, keepdims=True)
pres_max = np.max(D[:, :, 1], axis=1, keepdims=True)
D[:, :, 1] = (D[:, :, 1] - pres_min) / (pres_max - pres_min)

# 5.2. Estadísticos para sensores filtrados
D_filtrados = D[sensores_filtrados]
media = np.mean(D_filtrados, axis=(0,1))
mediana = np.median(D_filtrados, axis=(0,1))
std = np.std(D_filtrados, axis=(0,1))
print("\nMedia (Temp, Pres, Hum):", media)
print("Mediana (Temp, Pres, Hum):", mediana)
print("Desviación estándar (Temp, Pres, Hum):", std)
# Justificación: Estos valores resumen el comportamiento central y la dispersión de los sensores seleccionados.

# 6.1. Matriz de correlación para sensores filtrados
# Para calcular la correlación entre las variables, necesitamos que los datos estén en un formato donde
# las variables sean columnas y cada fila sea una observación (una lectura de sensor en un punto de tiempo).
# Aplanamos las dimensiones de sensor y tiempo.
D_filtrados_reshaped = D_filtrados.reshape(-1, D_filtrados.shape[-1])

# Ahora calculamos la matriz de correlación sobre el arreglo aplanado.
# 'rowvar=False' indica que las columnas representan variables.
matriz_correlacion = np.corrcoef(D_filtrados_reshaped, rowvar=False)

print("\nMatriz de correlación para sensores filtrados:\n", matriz_correlacion)
# Justificación: Se calcula la matriz de correlación para entender las relaciones lineales entre
# Temperatura, Presión y Humedad, considerando todas las observaciones de los sensores identificados.

# %%
# 6.2. Variable más correlacionada con la temperatura
# La primera fila/columna de la matriz de correlación (cuando rowvar=False) corresponde a la Temperatura.
# Queremos encontrar la variable con el valor absoluto más alto en la primera fila (excluyendo la correlación de Temp con Temp, que es 1).

# Obtenemos la fila de correlación de la temperatura
correlacion_temp = matriz_correlacion[0, :]

# Tomamos el valor absoluto y excluimos la correlación de Temperatura consigo misma
correlacion_temp_abs = np.abs(correlacion_temp[1:])

# Encontramos el índice del valor absoluto más grande (en la fila de correlación_temp_abs)
indice_max_correlacion = np.argmax(correlacion_temp_abs) + 1 # Sumamos 1 para obtener el índice original en la matriz

# Determinamos el nombre de la variable correspondiente
variables = ["Temperatura", "Presión", "Humedad"]
variable_mas_correlacionada = variables[indice_max_correlacion]
valor_max_correlacion = correlacion_temp[indice_max_correlacion] # Obtenemos el valor real de correlación

print(f"\nLa variable más correlacionada con la Temperatura en este subconjunto es: {variable_mas_correlacionada}")
print(f"Valor de correlación: {valor_max_correlacion:.4f}")

# Justificación: Se identifica la variable que presenta la relación lineal más fuerte (positiva o negativa) con la
# temperatura dentro del conjunto de datos de los sensores filtrados, analizando los coeficientes de correlación.

# 7.1. Para el sensor con mayor varianza en temperatura, calcula la matriz de covarianza entre sus tres variables
# Calculamos la varianza de temperatura por sensor (eje 1 = tiempo)
varianza_temp = np.var(D[:, :, 0], axis=1)

# Encontramos el índice del sensor con máxima varianza
sensor_max_var = np.argmax(varianza_temp)

print(f"\nSensor con mayor varianza en temperatura: {sensor_max_var}")
print(f"Varianza de temperatura: {varianza_temp[sensor_max_var]:.2f}")

# Extraemos los datos del sensor seleccionado (forma: [96, 3])
datos_sensor = D[sensor_max_var]

# Calculamos la matriz de covarianza (usamos rowvar=False porque columnas=variables)
matriz_cov = np.cov(datos_sensor, rowvar=False)

print("\nMatriz de covarianza del sensor seleccionado:")
print(matriz_cov)

#7.2 Realiza una descomposición en valores y vectores propios de la matriz de covarianza, e interpreta el resultado (¿qué variable aporta más a la variabilidad?)
# Calculamos autovalores y autovectores
autovalores, autovectores = np.linalg.eig(matriz_cov)

print("\nAutovalores (valores propios):", autovalores)
print("\nAutovectores (vectores propios):\n", autovectores)

# Encontramos el autovalor más grande
indice_max = np.argmax(autovalores)
autovector_principal = autovectores[:, indice_max]

# Identificamos la variable con mayor peso en el autovector principal
variable_principal = np.argmax(np.abs(autovector_principal))
nombres_variables = ["Temperatura", "Presión", "Humedad"]

print(f"\nLa variable que más aporta a la variabilidad es: {nombres_variables[variable_principal]}")
print(f"Autovalor asociado: {autovalores[indice_max]:.2f}")
print(f"Autovector principal: {autovector_principal}")